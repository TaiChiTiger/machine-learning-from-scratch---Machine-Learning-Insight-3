{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "5  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564   \n",
       "\n",
       "  train  \n",
       "1     T  \n",
       "2     T  \n",
       "3     T  \n",
       "4     T  \n",
       "5     T  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prostate = pd.read_csv(\"../../../datasets/prostate/prostate.data\",\n",
    "                       sep=\"\\t\", index_col=0)\n",
    "prostate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prostate.drop(\"train\", axis=1)[prostate[\"train\"] == \"T\"]\n",
    "test_data = prostate.drop(\"train\", axis=1)[prostate[\"train\"] == \"F\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data_std = scaler.fit_transform(train_data)\n",
    "test_data_std = scaler.transform(test_data)\n",
    "X_train = train_data_std[:, :-1]\n",
    "y_train = train_data_std[:, -1]\n",
    "X_test = test_data_std[:, :-1]\n",
    "y_test = test_data_std[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"线性回归\n",
    "    \n",
    "    参数：\n",
    "    -----\n",
    "    learning_rate: 在梯度下降中，更新权重所用的步长\n",
    "    epochs: 在梯度下降中，迭代所用的步数\n",
    "    \"\"\"\n",
    "    def __init__(self, epochs=200, learning_rate=0.1):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    # 均方差损失函数\n",
    "    def __mean_squared_error(self, X, W, y):\n",
    "        y_pred = X @ W\n",
    "        return np.sum((y - y_pred)**2) / len(y)\n",
    "    \n",
    "    # 负梯度\n",
    "    def __negative_gradient(self, X, W, y):\n",
    "        grad = -2 / len(y) * X.T @ (y - X @ W) \n",
    "        return -grad\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n, p = X.shape\n",
    "        X = np.c_[np.ones(n), X]\n",
    "        self.W = np.random.randn(p+1)\n",
    "        weight_history = [self.W.copy()]\n",
    "        loss = self.__mean_squared_error(X, self.W, y)\n",
    "        self.loss_history = [loss]\n",
    "        tol = 1e-5\n",
    "        for e in range(1, self.epochs+1):\n",
    "            neg_grad = self.__negative_gradient(X, self.W, y)  # 负梯度\n",
    "            self.W += self.learning_rate * neg_grad # 更新权重\n",
    "            weight_history.append(self.W.copy())\n",
    "            weight_change = np.sum(np.abs(np.abs(weight_history[-1]) - \\\n",
    "                                          np.abs(weight_history[-2])))\n",
    "            if weight_change < tol:\n",
    "                break          \n",
    "            loss = self.__mean_squared_error(X, self.W, y)\n",
    "            self.loss_history.append(loss)\n",
    "        if weight_change > tol and self.loss_history[-1] > tol:\n",
    "            print(\"Linear regression dosen't converge!\")\n",
    "                      \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n = len(X)\n",
    "        X_b = np.c_[np.ones(n), X]\n",
    "        y_pred = X_b @ self.W\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(epochs=500, learning_rate=0.1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(epochs=500)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本误差: 0.306\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_train)\n",
    "train_err = mean_squared_error(y_train, y_pred)\n",
    "print(\"训练样本误差: {:.3f}\".format(train_err)) # 均方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试样本误差: 0.363\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "test_err = mean_squared_error(y_test, y_pred)\n",
    "print(\"测试样本误差: {:.3f}\".format(test_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.44196670e-17,  5.93132150e-01,  2.42299177e-01, -1.18034828e-01,\n",
       "        1.75529770e-01,  2.56370758e-01, -2.39269742e-01, -1.72372841e-02,\n",
       "        2.29541816e-01])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 系数\n",
    "lr.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制历史损失值曲线\n",
    "loss_history = lr.loss_history\n",
    "plt.plot(range(len(loss_history)), loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 `Sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_lr = LinearRegression()\n",
    "sk_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本误差: 0.306\n"
     ]
    }
   ],
   "source": [
    "y_train_preds = sk_lr.predict(X_train)\n",
    "train_err = mean_squared_error(y_train, y_train_preds)\n",
    "print(\"训练样本误差: {:.3f}\".format(train_err)) # 均方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试样本误差: 0.363\n"
     ]
    }
   ],
   "source": [
    "y_test_preds = sk_lr.predict(X_test)\n",
    "test_err = mean_squared_error(y_test, y_test_preds)\n",
    "print(\"测试样本误差: {:.3f}\".format(test_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>变量</th>\n",
       "      <th>值</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lcavol</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lweight</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>-0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lbph</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svi</td>\n",
       "      <td>0.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lcp</td>\n",
       "      <td>-0.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gleason</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pgg45</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          变量      值\n",
       "0  Intercept  0.000\n",
       "1     lcavol  0.593\n",
       "2    lweight  0.242\n",
       "3        age -0.118\n",
       "4       lbph  0.176\n",
       "5        svi  0.256\n",
       "6        lcp -0.239\n",
       "7    gleason -0.017\n",
       "8      pgg45  0.230"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "variables = [\"Intercept\"] + list(train_data.iloc[:, :-1].columns)\n",
    "pd.DataFrame({\"变量\": variables, \"值\": np.r_[sk_lr.intercept_, sk_lr.coef_]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
